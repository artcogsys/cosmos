Search.setIndex({envversion:46,filenames:["api/cosmos","api/cosmos.analysis","api/cosmos.reinforcement_learning","api/cosmos.supervised_learning","api/index","index"],objects:{"":{cosmos:[0,0,0,"-"]},"cosmos.reinforcement_learning":{agents:[2,0,0,"-"],models:[2,0,0,"-"],networks:[2,0,0,"-"],tasks:[2,0,0,"-"],unit_test:[2,0,0,"-"],world:[2,0,0,"-"]},"cosmos.reinforcement_learning.agents":{REINFORCEAgent:[2,1,1,""]},"cosmos.reinforcement_learning.agents.REINFORCEAgent":{reset_state:[2,2,1,""],score_function:[2,2,1,""],train:[2,2,1,""]},"cosmos.reinforcement_learning.models":{ActorModel:[2,1,1,""],Model:[2,1,1,""]},"cosmos.reinforcement_learning.models.ActorModel":{"__call__":[2,2,1,""],predict:[2,2,1,""]},"cosmos.reinforcement_learning.models.Model":{has_state:[2,3,1,""],predict:[2,2,1,""],reset_state:[2,2,1,""]},"cosmos.reinforcement_learning.networks":{MLP:[2,1,1,""],RNN:[2,1,1,""]},"cosmos.reinforcement_learning.networks.MLP":{has_state:[2,3,1,""]},"cosmos.reinforcement_learning.networks.RNN":{has_state:[2,3,1,""],reset_state:[2,2,1,""]},"cosmos.reinforcement_learning.tasks":{EvidenceTask:[2,1,1,""]},"cosmos.reinforcement_learning.tasks.EvidenceTask":{reset:[2,2,1,""],step:[2,2,1,""]},"cosmos.reinforcement_learning.unit_test":{UnitTest:[2,1,1,""]},"cosmos.reinforcement_learning.unit_test.UnitTest":{test_stateful_network:[2,2,1,""],test_stateless_network:[2,2,1,""]},"cosmos.reinforcement_learning.world":{World:[2,1,1,""]},"cosmos.reinforcement_learning.world.World":{test:[2,2,1,""],train:[2,2,1,""]},"cosmos.supervised_learning":{agents:[3,0,0,"-"],iterators:[3,0,0,"-"],models:[3,0,0,"-"],networks:[3,0,0,"-"],unit_test:[3,0,0,"-"],world:[3,0,0,"-"]},"cosmos.supervised_learning.agents":{SupervisedAgent:[3,1,1,""]},"cosmos.supervised_learning.agents.SupervisedAgent":{"__call__":[3,2,1,""],reset_state:[3,2,1,""],test:[3,2,1,""],train:[3,2,1,""]},"cosmos.supervised_learning.iterators":{RandomIterator:[3,1,1,""],SequentialIterator:[3,1,1,""]},"cosmos.supervised_learning.iterators.RandomIterator":{next:[3,2,1,""]},"cosmos.supervised_learning.iterators.SequentialIterator":{next:[3,2,1,""]},"cosmos.supervised_learning.models":{Classifier:[3,1,1,""],Model:[3,1,1,""],Regressor:[3,1,1,""]},"cosmos.supervised_learning.models.Model":{"__call__":[3,2,1,""],has_state:[3,3,1,""],predict:[3,2,1,""],reset_state:[3,2,1,""]},"cosmos.supervised_learning.networks":{MLP:[3,1,1,""],RNN:[3,1,1,""]},"cosmos.supervised_learning.networks.MLP":{has_state:[3,3,1,""]},"cosmos.supervised_learning.networks.RNN":{has_state:[3,3,1,""],reset_state:[3,2,1,""]},"cosmos.supervised_learning.unit_test":{UnitTest:[3,1,1,""]},"cosmos.supervised_learning.unit_test.UnitTest":{test_gpu:[3,2,1,""],test_stateful_network:[3,2,1,""],test_stateless_network:[3,2,1,""]},"cosmos.supervised_learning.world":{World:[3,1,1,""]},"cosmos.supervised_learning.world.World":{test:[3,2,1,""],train:[3,2,1,""]},cosmos:{analysis:[1,0,0,"-"],reinforcement_learning:[2,0,0,"-"],supervised_learning:[3,0,0,"-"]}},objnames:{"0":["py","module","Python module"],"1":["py","class","Python class"],"2":["py","method","Python method"],"3":["py","attribute","Python attribute"]},objtypes:{"0":"py:module","1":"py:class","2":"py:method","3":"py:attribute"},terms:{"7esutton":2,"__call__":[2,3],"case":[2,3],"class":[2,3],"final":[],"function":3,"int":[2,3],"new":2,"return":[2,3],"true":[],aac:[],action:2,actor:2,actorcriticag:[],actormodel:2,actual:3,advantag:[],after:[2,3],agent:[],algorithm:2,alwai:2,analysi:[],appli:3,associ:[],base:[2,3],baselin:[],batch:3,batch_siz:3,beta:[],blog:2,book:2,bookdraft2016sep:2,bool:[2,3],call:[],can:3,care:[2,3],chain:[2,3],chainer:[2,3],check:[2,3],classif:3,classifi:3,com:2,comput:[2,3],contain:3,correctli:2,critic:[],cumul:2,cutoff:[2,3],dai:2,data:[2,3],decid:2,decis:2,dennybritz:2,deriv:2,determin:2,differ:3,dmm:2,doe:2,done:2,each:[2,3],entropi:[],environ:[],epoch:[2,3],estim:[],evalu:2,evid:2,evidencetask:2,fals:[],footask:[],forward:3,from:2,fulli:[],gamma:2,gener:[2,3],get:2,get_observ:[],get_stat:[],github:2,given:[],gpu:[2,3],gradient:[],ground:2,has_stat:[2,3],http:2,idx:[],implement:2,index:[4,5],inf:[],input:3,instead:[],integr:2,iter:[],label:3,lambda:3,learn:[2,3],link:[2,3],list:3,log:2,log_derivative_trick:2,loss:[2,3],loss_funct:3,machin:2,master:2,method:[],methodnam:[2,3],minibatch:3,mlp:[2,3],mode:3,model:[],modulo:[2,3],more:[2,3],multilay:[2,3],n_batch:[],n_epoch:3,n_hidden:[2,3],n_input:[2,3],n_output:[2,3],n_step:2,net:[2,3],network:[],next:3,none:[2,3],note:[],number:[2,3],object:[2,3],observ:2,onli:2,optim:[2,3],option:3,out:[2,3],output:3,output_funct:3,over:3,page:[4,5],param:3,paramet:[2,3],pdf:2,perceptron:[2,3],persist:[2,3],point:3,polici:2,policygradi:2,post:3,predict:[2,3],predictor:2,present:2,previou:[],probabilist:2,problem:3,procedur:[2,3],process:3,produc:2,random:3,randomiter:3,raw:3,regress:3,regressor:3,reinforc:2,reinforceag:2,reinforcement_learn:[],repres:3,requir:2,reset:[2,3],reset_st:[2,3],result:[2,3],reward:2,rnn:[2,3],run:[2,3],runtest:[2,3],save:[2,3],score:2,score_funct:2,search:[4,5],sequentialiter:3,shakirm:2,simpl:2,snapshot:[2,3],softmax:3,some:[2,3],state:[2,3],stateless:[2,3],step:2,submodul:[],subset:3,supervis:3,supervised_learn:[],supervisedag:3,take:[2,3],target:3,task:0,test:[2,3],test_gpu:3,test_it:3,test_stateful_network:[2,3],test_stateless_network:[2,3],testcas:[2,3],than:3,thi:2,time:3,train:[2,3],train_it:3,tree:2,trick:2,truth:2,ualberta:2,unit_test:[],unittest:[2,3],valu:[],variabl:2,veri:2,webdoc:2,when:2,whether:[2,3],which:[2,3],world:[],wrap:[2,3],wrapper:[2,3],www:2},titles:["cosmos package","cosmos.analysis package","cosmos.reinforcement_learning package","cosmos.supervised_learning package","Welcome to cosmos&#8217;s documentation!","Welcome to Cosmos&#8217;s documentation!"],titleterms:{agent:[2,3],analysi:1,content:[0,1,2,3],cosmo:[0,1,2,3,4,5],document:[4,5],indic:[4,5],iter:3,model:[2,3],modul:[0,1,2,3],network:[2,3],packag:[0,1,2,3],reinforcement_learn:2,submodul:[2,3],subpackag:0,supervised_learn:3,tabl:[4,5],task:2,unit_test:[2,3],welcom:[4,5],world:[2,3]}})